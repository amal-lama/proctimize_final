{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28bdb559",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# scripts/extract.py (ingest & clean portion)\n",
    "import pandas as pd\n",
    "import re\n",
    "from pathlib import Path\n",
    "\n",
    "RAW_XLSX = Path(\"data/raw.xlsx\")\n",
    "ALIASES = {\"X\", \"Drug X\", \"GenericX\", \"BrandX\"}  # <- expand with your synonyms\n",
    "\n",
    "def load_and_clean():\n",
    "    df = pd.read_excel(RAW_XLSX, engine=\"openpyxl\")\n",
    "    # Normalize column names\n",
    "    df = df.rename(columns={c: c.strip().lower() for c in df.columns})\n",
    "    required = [\"id\", \"author_name\", \"text\", \"source_type\", \"date\"]\n",
    "    missing = [c for c in required if c not in df.columns]\n",
    "    if missing:\n",
    "        raise ValueError(f\"Missing columns: {missing}\")\n",
    "\n",
    "    # Filter by any alias of X\n",
    "    pattern = re.compile(r\"\\b(\" + \"|\".join(re.escape(a) for a in ALIASES) + r\")\\b\", flags=re.I)\n",
    "    df = df[df[\"text\"].fillna(\"\").str.contains(pattern)]\n",
    "\n",
    "    # Basic cleaning\n",
    "    def clean_text(t):\n",
    "        t = re.sub(r\"http\\S+\", \"\", str(t))         # remove URLs\n",
    "        t = re.sub(r\"[@#]\\w+\", \"\", t)              # remove @handles and #hashtags (optional)\n",
    "        t = re.sub(r\"\\s+\", \" \", t).strip()\n",
    "        return t\n",
    "    df[\"clean_text\"] = df[\"text\"].map(clean_text)\n",
    "\n",
    "    return df\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
